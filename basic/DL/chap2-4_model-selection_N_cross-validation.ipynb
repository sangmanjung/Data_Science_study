{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn API training #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __train_test_split( )__  \n",
    "  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data,...)\n",
    "    - test_size: 전체 데이터에서 테스트 데이터 크기 결정 (default: 0.25)\n",
    "    - train_size: 전체 데이터에서 학습용 데이터 크기 결정\n",
    "    - shuffle: 데이터를 분리하기 전에 데이터를 미리 섞을지 결정 (default: True)\n",
    "    - random_state: 함수를 호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation  \n",
    "  \n",
    "* training dataset에서 validation dataset을 따로 분리함\n",
    "  \n",
    "* __K fold cross validation__  \n",
    "\n",
    "  __[작동원리]__\n",
    "  \n",
    "  - K = 5인 경우 전체 train_data를 4개의 학습 데이터, 1개의 검증 데이터로 나누어 모델 학습/검증을 시행\n",
    "    \n",
    "  - 그러면 총 5번의 검증 평가가 이루어짐  \n",
    "      평가1: 1 to 4(train),5(valid), 평가2: 2 to 5(train),1(valid), 평가3: 3,4,5,1(train), 2(valid) .....\n",
    "  - 교차 검증 최종 평가는 평가1 부터 평가 5까지의 결과의 평균으로 계산\n",
    "  \n",
    "  __[종류]__\n",
    "  \n",
    "  - __K fold__ : 일반적인 위의 방법의 K 폴드\n",
    "  \n",
    "  - __Stratified K fold__ : 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식. 학습 데이터와 검증 데이터 세트가 갖는 레이블 분포도가 유사하도록 검증 데이터 추출\n",
    "  \n",
    "  __[프로세스]__\n",
    "  \n",
    "  - 1. 폴드 세트 설정 (K = ?)\n",
    "  \n",
    "  - 2. for loop에서 반복적으로 학습/검증 데이터 추출 및 학습과 예측 수행\n",
    "  \n",
    "  - 3. 폴드 세트별로 예측 성능의 평균을 최종 성능 평가 지표로 사용  \n",
    "    \n",
    "    \n",
    "* __cross_val_score( )__ : 한꺼번에 위의 CV 프로세스를 실행 가능한 함수  \n",
    "  \n",
    "* __GridSearchCV( )__ : 교차 검증 및 최적 하이퍼 파라미터 튜닝을 한번에 실행 가능한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris() # data load\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "DT_df = DecisionTreeClassifier(random_state = 111) # model load\n",
    "\n",
    "# generate K fold instance\n",
    "kfold = KFold(n_splits = 5) # K = 5 (default = 3)\n",
    "cross_val_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __K fold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #1 cross_validation accuracy: 1.0, train_data_size: 120, valid_data_size: 30\n",
      "#1 validation set index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      " #2 cross_validation accuracy: 0.9667, train_data_size: 120, valid_data_size: 30\n",
      "#2 validation set index: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      " #3 cross_validation accuracy: 0.8667, train_data_size: 120, valid_data_size: 30\n",
      "#3 validation set index: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      " #4 cross_validation accuracy: 0.9333, train_data_size: 120, valid_data_size: 30\n",
      "#4 validation set index: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      " #5 cross_validation accuracy: 0.7333, train_data_size: 120, valid_data_size: 30\n",
      "#5 validation set index: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ### Mean validation accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "N = 0\n",
    "# KFold의 .split()을 이용하여 행 index를 array로 반환\n",
    "for train_index, test_index in kfold.split(features): # K fold loop\n",
    "    # KFold index를 가지고 실제 data의 해당 index 값을 반환\n",
    "    X_train,X_test = features[train_index], features[test_index]\n",
    "    y_train,y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    DT_df.fit(X_train,y_train)\n",
    "    pred = DT_df.predict(X_test)\n",
    "    N += 1\n",
    "    \n",
    "    # 반복마다 accuracy 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    # 반복마다 결과 출력\n",
    "    print('\\n #{0} cross_validation accuracy: {1}, train_data_size: {2}, valid_data_size: {3}'\n",
    "          .format(N,accuracy,train_size,test_size))\n",
    "    print('#{0} validation set index: {1}'.format(N,test_index))\n",
    "    \n",
    "    cross_val_accuracy.append(accuracy) # 해당 K 마다 계산된 accuracy 저장\n",
    "    \n",
    "print('\\n ### Mean validation accuracy: ',np.mean(cross_val_accuracy)) # 최종 CV 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Stratified K fold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "'''\n",
    "## K fold를 이용하기 위해선 학습과 검증 데이터 내의 label 개수가 거의 유사한지 check 해야함\n",
    "'''\n",
    "\n",
    "iris_df['label'].value_counts() # 레이블 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cross Validation: 1\n",
      "train data distribution: \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "test data distribution: \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## Cross Validation: 2\n",
      "train data distribution: \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "test data distribution: \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "## Cross Validation: 3\n",
      "train data distribution: \n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "test data distribution: \n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Kfold에선  K = 3인 경우 전체 데이터가  150이므로 50식 쪼개면 레이블 0,1,2가 고루 학습되지 않음\n",
    "#kfold = KFold(n_splits = 3)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "S_kfold = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "N = 0\n",
    "for train_index, test_index in S_kfold.split(iris_df,iris_df['label']): # S_Kfold에선 반드시 target값도 포함\n",
    "    N += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    \n",
    "    print('## Cross Validation: {}'.format(N))\n",
    "    print('train data distribution: \\n', label_train.value_counts())\n",
    "    print('test data distribution: \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __cross_val_score( )__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_valid_accuracy:  [0.9804 0.9216 0.9792]\n",
      "mean_cross_valid_accuracy:  0.9604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "DT = DecisionTreeClassifier(random_state = 111)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표를 정확도(accuracy), 교차검증 세트(K)는 3개로 분할\n",
    "scores = cross_val_score(DT,data,label,scoring = 'accuracy',cv = 3)\n",
    "print('cross_valid_accuracy: ',np.round(scores,4))\n",
    "print('mean_cross_valid_accuracy: ',np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __GridSearchCV( )__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,\n",
    "                                                 test_size = 0.2, random_state = 111)\n",
    "\n",
    "DT = DecisionTreeClassifier() # 결정트리\n",
    "\n",
    "# hyper parameters를 dictionary 형태로 설정\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\92nor\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.691667                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.691667                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.950000                2   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.950000                2   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.958333                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.950000                2   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.690476           0.692308           0.692308  \n",
       "1           0.690476           0.692308           0.692308  \n",
       "2           0.904762           0.948718           1.000000  \n",
       "3           0.904762           0.948718           1.000000  \n",
       "4           0.904762           0.974359           1.000000  \n",
       "5           0.904762           0.948718           1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# param_grid의 하이퍼 파라미터들을 3개의 학습/검증 fold로 나누어서 테스트 수행\n",
    "# refit = True 는 가장 좋은 파라미터 설정으로 재학습 시키기 위함\n",
    "grid_DT = GridSearchCV(DT,param_grid = parameters, cv = 3,\n",
    "                       refit = True, return_train_score = True)\n",
    "\n",
    "grid_DT.fit(X_train,y_train)\n",
    "\n",
    "# GridSearchCV 결과는 GridSearchCV.cv_results_라는 딕셔너리로 저장.\n",
    "scores_df = pd.DataFrame(grid_DT.cv_results_) # 보기 좋게 DataFrame으로 변환\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score',\n",
    "          'split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_min_samples_split', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_DT.cv_results_.keys() # 가지고 있는 key값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_split': 2}\n",
      "0.9583333333333334\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')\n",
      "test accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "print(grid_DT.best_params_)\n",
    "print(grid_DT.best_score_)\n",
    "print(grid_DT.best_estimator_)\n",
    "est = grid_DT.best_estimator_\n",
    "pred = est.predict(X_test) # 파라미터 튜닝 완료된 최적 모델을 가지고 predict 가능\n",
    "print('test accuracy: {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
